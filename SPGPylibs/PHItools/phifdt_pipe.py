import json
import numpy as np 
import os, os.path, datetime, subprocess
#from astropy.io import fits as pyfits
#from time import sleep
#from scipy.ndimage import gaussian_filter#, rotate
#from scipy.interpolate import interp1d
#from scipy.optimize import curve_fit
from .tools import *
from .phi_fits import *
from .phi_gen import *
from .phi_reg import *
from .phi_rte import *
#from .phi_utils import newton,azimutal_average,limb_darkening,genera_2d,find_string
from .phifdt_pipe_modules import phi_correct_dark,phi_correct_prefilter,phi_apply_demodulation,\
    crosstalk_ItoQUV,cross_talk_QUV,crosstalk_ItoQUV2d,phi_correct_ghost,phi_correct_fringes,\
    generate_level2,phi_load_dark,phi_load_flat,phi_apply_dark

import SPGPylibs.GENtools.plot_lib as plib
import SPGPylibs.GENtools.cog as cog

from platform import node
MILOS_EXECUTABLE = 'milos.'+node().split('.')[0]+'.x'

#--------  GLOBALS  --------  
PLT_RNG = 5
#---------------------------

def phifdt_pipe(json_input = None, 
    data_f: str = None,  dark_f: str = None,  flat_f: str = None,
    input_data_dir: str = './',   output_dir:str = './',
    instrument: str = 'FDT40',
    flat_c:bool = True, dark_c:bool = True, ItoQUV:bool = False, VtoQU:bool = False, ind_wave:bool = False,                         #correction options
    hough_params:list = [250, 800, 100], 
    norm_f:bool = False, flat_scaling:float = 1.,                                          #flatfield options
    prefilter:bool = True, prefilter_fits:str = '0000990710_noMeta.fits',
    realign:bool = False, verbose:bool = True, shrink_mask:int = 2, correct_fringes:str = False,
    correct_ghost:bool = False, putmediantozero:bool = True,
    rte = False, debug:bool = False, nlevel:float = 0.3, center_method:str = 'circlefit',
    do2d = 0, outfile = None, #not in use
    cmilos = 'pymilos'
    ) -> int: 
    
    '''
    Parameters
    ----------
    :param str data_f: 

    Input parameters
    ----------    
    json_input = json input (for convenience). All parameters are then described there).
    data_f = data_f : string
        Fits file of the raw FDT data  (for path use input_data_dir keyword)
    dark_f = dark_f : string
        Fits file of a Valid dark file (processed dark) (including path, if necessary)
    flat_f = flat_f : string
        Fits file of a Valid FDT flatfield (including path, if necessary)

    input_data_dir: directory where input data is located. Default is local directory
    output_dir: output directory. If default, takes local './'  

    IMPORTANT: dark_f, flat_f, and prefilter file must be provided with the FULL PATH. 
               the data has to be provided as a list of files (fits) and the directory via "input_data_dir = "
        The output directories (Depending on RTE on or off) are
        A)  directory + Level 2: reduced raw data L2+ilam plus RTE output (so far, BLOS, VLOS and SO1: continuum) 
        B)  directory + Level 2 + png: png figures of the RTE output (so far, BLOS and VLOS) 
        B)  directory + Level 2 + npz: NPZ (python) reduced raw data L2
        
    ** OPTIONAL ARGUMENTS **

    instrument = 'FDT40' : select the instrument and PMP temperature (for demod)
        -> implemented cases: -- 'FDT40','FDT45' --
    flat_c = True : default is to apply flat field correction to the data
    dark_c = True : default is to apply dark field correction to the data
    norm_f = False : To normalize flats internally to the mean value of 5% of the disk (central) intensity  
    flat_scaling = 1.0 : flat scaling (flat = flat / flat_scaling) 
    flat_index = None : in case you want a particular flat to be applied at another wave, e.g.,
        flat_index = [5,1,2,3,4,0] exchange the first and last wave flats
        This is for testing stuff, mainly. 
        #DEPRECATED in MArch 2022 (Not useful)
    prefilter = 1 : To correct for the prefilter 
    prefilter_fits = '../RSW1/0000990710_noMeta.fits' : User should provide prefilter data fits file location
    realign = False : bool
        Realign all images before demodulating using FFT 
    ind_wave = False : bool
        Correct crosstalk from I to QUV for individual wavelengths
    vervose: True prints a lot of stuff (and plots)
    shrink_mask = 2: 'Number of pixels to contract the sun mask for output of RTE'
    correct_fringes = False: Fringe correction
        'manual': first FM version. Freq, mask applied to all images with fixed frequencies
        'auto' : calculate fringes freq. automatically (in development).
    correct_ghost = False; Correcto ghost images
    putmediantozero=True; puts median value to zero before RTE
    rte = False: Run RTE     if rte == 'RTE' or rte == 'CE' or rte == 'CE+RTE':
        'RTE': RTE only
        'CE+RTE': RTE with classical estiamtes
        'CE': Only classical estimates
        'cog': Only Center of gravity (To be implemented)
    ItoQUV= False: apply crostalk correction from Stokes I to Stokes Q, U, and V.
    VtoQU= False: apply crostalk correction from Stokes V to Stokes Q and U.
    nlevel = 0.3: Noise level above which to evaluate cross_talk_VQU (To be implemented)

    center_method = ['circlefit','hough']
        Default is 'circlefit'. If set to 'hough' uses the given find_center parameters 
        If find_center is set to None then uses header information, in any case
    hough_params = [250, 800, 100]; inner_radius = 250, outer_radius = 600, steps = 100 : initial values for finding sun center

    verbose: increase the verbosity (many plots here) - default False

    Returns
    -------
    0 if fail, 1 any other case 

    Raises
    ------

    References
    ----------
    
    Examples
    --------
    >>> import SPGPylibs as spg

    Notes
    -----
    This program is not optimized for speed. It assumes that input data is 6 wavelength.
    C-MILOS must be compiled in each specific machine (C)
    The software update some of the information in the fits keyword:

    TODO:
    # data_f -> input data (single file for FDT - ADD MULTIPLE FILES!!!! )
    keyword to provide fixed cross-talk coefficients 
    keyword to provide fixed data normalization (based on a first obs) 
    # pending to add class stile (for module development)

	FDT pipeline steps:

    1- Read data
    2- Check dimensions (open to bugs since only few data were tested)
    3- Read flats
    4- Read and correct dark field (taking into account the scaling)
    5- Find center of the Sun in the data for masking and ghost correction
    6- get wavelength sampling from header
    7- move the continuum to the blue (if needed) in flat and data
    8- interpolate flats (Not implemented yet - in case of deviations in voltage)
    9- Correct flat-field
    9- Correct prefilter - needs prefilter data file!
    9- Correct ghost (complex step) [NEEDED in FM - high priority]
    10- realign data before demodulation [NEEDED in FM - low priority]
    11- Demodulate data using appropriate dem matrix
    12- Normalize to average continuum [NEEDED in FM - low priority - determine the Icont automatically]
    13- correct cross-talk from I to QUV [NEEDED in FM - evaluation of these automatically - mid priority]
    14- correct cross-talk from V to QU (interactive) [NEEDED in FM - evaluation of these automatically - mid priority]
    15- correct cross-talk from I to QUV in 2D (do not use this, your PC will have a hangover)
    16- Fringes correction [NEEDED in FM -TBD]
    17- median to zero [NEEDED in FM]
    18- save
    19- RTE (RTE or CE or CE+RTE)
    20- plots

    Keywords in the header (modified or added) within this program:
 
    CAL_DARK =             26181001 / Onboard calibrated for dark field ! Dark correction ( DID/file of dark if True) 
    CAL_FLAT =             26181101 / Onboard calibrated for gain table ! Dark correction ( DID/file of flat if True)             
    CAL_PRE  =             Prefilter / Prefilter correction ( DID/file of flat if True)                    
    CAL_GHST=              Prefilter / Ghost correction ( name+version of py module if True )           
    CAL_REAL=              Prefilter / Prealigment of images before demodulation ( name+version of py module if True )             
    CAL_IPOL=               990510 / Onboard calibrated for instrumental polarizatio ! demodulation ( DID of demod matrix if True ) - demod matrix may be 4x4 or 2048x2048x4x4
    CAL_CRT0=               float / cross-talk from I to Q (slope value, wrt normalized data in python) 
    CAL_CRT1=               float / cross-talk from I to Q (off-set value, wrt normalized data in python) 
    CAL_CRT2=               float / cross-talk from I to U (slope value, wrt normalized data in python) 
    CAL_CRT3=               float / cross-talk from I to U (off-set value, wrt normalized data in python) 
    CAL_CRT4=               float / cross-talk from I to V (slope value, wrt normalized data in python) 
    CAL_CRT5=               float / cross-talk from I to V (off-set value, wrt normalized data in python) 
    CAL_CRT6=               float / cross-talk from V to Q (slope value, wrt normalized data in python) 
    CAL_CRT7=               float / cross-talk from V to Q (off-set value, wrt normalized data in python) 
    CAL_CRT8=               float / cross-talk from V to U (slope value, wrt normalized data in python) 
    CAL_CRT9=               float / cross-talk from V to U (off-set value, wrt normalized data in python) 
    CAL_NORM=               990510 / Normalization constant PROC_Ic)
    CAL_FRIN=               990510 / Fringe correction ( name+version of py module if True )  TBD (posibly we need the freqs.)  
   * CAL_PSF=                990510 / Onboard calibrated for instrumental PSF  ! TBD
    CAL_RTE=                990510 / ok
   * CAL_SCIP= 'None'               / Onboard scientific data analysis
   * RTE_ITER=           4294967295 / Number RTE inversion iterations

    (*) are not touched in this software.

    Keywords CRPIX1 and CRPIX2 are updated following the new center calculation within the pipeline. Old values are stored in the history.
    Keywords CRVAL1 and CRVAL2 are NOT updated but should be SET to zero!!!!

    '''

    version = 'V1.0 July 2021'
    version = 'V1.0 13th September 2021'
    version = 'V1.0 3th November 2021'
    #added json configuration and modify all keyword names to be consistent with HRT pipe
    version = 'V1.0 10th March 2022'
    #major revision ongoing (reordesing, creatils call onjetc, parallel stuff, auto C compilation, etc)

    version_cmilos = 'CMILOS v0.91 (July - 2021)'

    printc('---------------------------------------------------------------',bcolors.OKGREEN)
    printc(' PHI FDT data reduction software (beta version)                ',bcolors.OKGREEN)
    printc('  Pipeline version: '+ version,bcolors.OKGREEN)
    printc('  CMILOS version: '+ version_cmilos,bcolors.OKGREEN)
    printc('---------------------------------------------------------------',bcolors.OKGREEN)

    if json_input:

        # =========================================================================== #
        # READING CONFIG FILE AND PRINTING
        printc('--------------------------------------------------------------',bcolors.OKGREEN)
        printc(' Reading config json file '+json_input,bcolors.OKGREEN)
        with open(json_input) as j:
            CONFIG = json.load(j)

        verbose = CONFIG['verbose']
        input_data_dir = CONFIG['input_data_dir']
        data_f = CONFIG['data_f']
        shrink_mask = CONFIG['shrink_mask']
        center_method = CONFIG['center_method'] 
        hough_params = CONFIG['hough_params']
        instrument = CONFIG['instrument']
        flat_f = CONFIG['flat_f']
        dark_f = CONFIG['dark_f']
        dark_c = CONFIG['dark_c']
        flat_c = CONFIG['flat_c']
        flat_index = CONFIG['flat_index']
        norm_f = CONFIG['norm_f']
        flat_scaling = CONFIG['flat_scaling']
        prefilter_fits = CONFIG['prefilter_fits']
        prefilter = CONFIG['prefilter']
        output_dir = CONFIG['output_dir']
        rte = CONFIG['rte']
        correct_fringes = CONFIG['correct_fringes']
        correct_ghost = CONFIG['correct_ghost']
        putmediantozero = CONFIG['putmediantozero']
        debug = CONFIG['debug']
        ItoQUV = CONFIG['ItoQUV']
        VtoQU = CONFIG['VtoQU']
        realign = CONFIG['realign']
        ind_wave = CONFIG['ind_wave']
        nlevel = CONFIG['nlevel']
        cmilos = CONFIG['cmilos']

        import pprint
        # Prints the nicely formatted dictionary
        pprint.pprint(CONFIG)#, sort_dicts=False)
    else:
        printc(' Using sequencial mode ',bcolors.OKGREEN)
        printc('    (hopefully with the right inputs since ERROR handling is not yet fully in place) ',bcolors.OKGREEN)

    #CHECK MILOS STATUS IF RTE
    if rte != False:
        #check cmilos option
        #defauls is pymilos so check if pymilos can be loaded
        rteok = False
        if cmilos == 'pymilos':
            try:
                from .cmilos import pymilos
                pymilosloadok = True
                printc("Using pymilos for RTE",color=bcolors.WARNING)
                rteok = True
            except:
                printc("unable to import pymilos version within phi_rte.",color=bcolors.FAIL)
                printc("   User did not specify cmilos option [''pymilos'' or ''cmilos''] so default is pymilos.",color=bcolors.WARNING)
                printc("   To compile pymilos go to cmilos folder and run make cython-build or make build.",color=bcolors.WARNING)
                pymilosloadok = False
                try:
                    import pymilos
                except:
                    printc("Trying to load pymilos from enviroment also failed. ",color=bcolors.WARNING)
                    printc("   phifdt_pipe.py will look for classical cmilos executable",color=bcolors.WARNING)
                    pymilosloadok = False

        #check if there is an executable:
        if cmilos != 'pymilos' or not(pymilosloadok):
            try:
                CMILOS_LOC = os.path.realpath(__file__) 
                CMILOS_LOC = CMILOS_LOC[:CMILOS_LOC.rfind('/')-len(CMILOS_LOC)+1] + 'cmilos/'
                if os.path.isfile(CMILOS_LOC+MILOS_EXECUTABLE):
                    printc("cmilos executable ",MILOS_EXECUTABLE," located at:", CMILOS_LOC,color=bcolors.WARNING)
                else:
                    raise ValueError(MILOS_EXECUTABLE, CMILOS_LOC)
                rteok = True
            except ValueError as err:
                printc('Cannot find cmilos executable: ',color=bcolors.FAIL)
                printc('Executable: ',err.args[0],color=bcolors.WARNING)
                printc('Location  : ',err.args[1],color=bcolors.WARNING)
                printc(" -----------  STOPING ",color=bcolors.FAIL)

            cmilos = CMILOS_LOC+"./"+MILOS_EXECUTABLE
            cmilos = fix_path(cmilos)
        if rteok == False:
            return


    # STEP 1
    #-----------------
    # READ DARK DATA
    #-----------------
    if dark_c:
        dark, dark_header, dark_scale, dark_DID = phi_load_dark(dark_f)
        #data, header  = phi_correct_dark(dark_f,data,header,data_scale,verbose = verbose)
    else:
        printc('-->>>>>>> No darks mode                    ',color=bcolors.WARNING)

    # STEP 2
    #-----------------
    # READ FLAT FIELDS
    #-----------------

    if flat_c:
        flat, flat_header, flat_scale, flat_DID = phi_load_flat(flat_f)
        flat = np.ascontiguousarray(flat)

        if verbose:
            plib.show_one(flat[0,:,:],xlabel='pixel',ylabel='pixel',title='Flat first image raw (1 of 24)',cbarlabel='Any (as input)',save=None,cmap='gray')

        printc('-->>>>>>> Obtaining voltages from flats ',color=bcolors.OKGREEN)
        wave_axis_f,voltagesFlat,tunning_constant_f,cpos_f,ref_wavelength_f = fits_get_sampling(flat_f) 

        printc('          FLAT FG voltages: ',voltagesFlat,color=bcolors.OKBLUE)
        printc('          FLAT Continuum position at wave: ', cpos_f,color=bcolors.OKBLUE)
        printc('          FLAT ref_wavelength [mA]: ',ref_wavelength_f,color=bcolors.OKBLUE)
        printc('          FLAT wave axis [mA]: ',wave_axis_f,color=bcolors.OKBLUE)
        printc('          FLAT wave axis - ref_wavelength [mA]: ',wave_axis_f - ref_wavelength_f,color=bcolors.OKBLUE)
        dummy_1 = (voltagesFlat-np.roll(voltagesFlat,-1))*(tunning_constant_f*1000)
        dummy_2 = np.sort(np.abs(dummy_1))
        sampling_f = np.mean(dummy_2[0:-2])
        printc('          FLAT average sampling [mA]: ',sampling_f,color=bcolors.OKBLUE)

    #-----------------
    # ROLL FLAT IF CONTINUUM IS IN DIFFERENT POSITION #TODO Take into account in the reduction (-4,-3,-2,-1, etc...)
    # default will be to have the continuum in the blue (first wavelength) ALWAYS!!!
    # Probably before demodulation and flat is better!!!!
    #-----------------

        if cpos_f != 0:
            printc('          Rolling flat to move continuum from right (red) to left (blue)',color=bcolors.WARNING)
            if voltagesFlat[cpos_f] < voltagesFlat[0]:
                printc('            The continuum was TAKEN in the BLUE, stored in the RED, but we want it in the BLUE *',color=bcolors.WARNING)
                flat = np.roll(flat,4,axis=0)
                voltagesFlat = np.roll(voltagesFlat,1,axis=0)
                wave_axis_f = np.roll(wave_axis_f,1,axis=0)

            elif voltagesFlat[cpos_f] > voltagesFlat[0]:
                printc('            The continuum was TAKEN in the RED but we want it in the BLUE',color=bcolors.WARNING)
                # printc('            * Notice that this is necessary for the FLAT correction',color=bcolors.FAIL)
                # printc('            *  but the wavelength axis has changed the continuum point *',color=bcolors.FAIL)
                flat = np.roll(flat,4,axis=0)
                voltagesFlat = np.roll(voltagesFlat,1,axis=0)
                wave_axis_f = np.roll(wave_axis_f,1,axis=0)
            else:
                printc('            * NO ROLLING *',color=bcolors.FAIL)

            cpos_f = 0
            printc('          New Flat FG voltages: ',voltagesFlat,color=bcolors.OKBLUE)
            printc('          NEW Flat continuum position at wave: ', cpos_f,color=bcolors.OKBLUE)
            printc('          NEW Flat data wave axis [mA]: ',wave_axis_f,color=bcolors.OKBLUE)

        #CHANGE TO 4D      
        zf,yf,xf = flat.shape
        flat = np.reshape(flat,(zf//4,4,yf,xf))

    else:
        printc('-->>>>>>> No flats mode                    ',color=bcolors.WARNING)

    # STEP 3
    #-----------------
    # READ DATA
    #-----------------
    
    data_filename = input_data_dir + data_f

    if os.path.isfile(data_filename):
        print("File exist")
    else:
        print("File not exist")

    try:
        data, header = fits_get(data_filename)
        printc('-->>>>>>> Reading Data file: '+data_filename,color=bcolors.OKGREEN)
        #
        # PXBEG1  =                  385 ; First read-out pixel in dimension 1            
        # PXEND1  =                 1664 ; Last read-out pixel in dimension 1             
        # PXBEG2  =                  385 ; First read-out pixel in dimension 2            
        # PXEND2  =                 1664 ; Last read-out pixel in dimension 2             

        DID = header['PHIDATID']
        ACC = header['ACCACCUM']
        printc('-->>>>>>> data DID '+DID,color=bcolors.OKGREEN)
        printc('          DATA IS DIVIDED by 256.   ',color=bcolors.OKGREEN)
        printc('-->>>>>>> Reshaping data to [wave,Stokes,y-dim,x-dim] ',color=bcolors.OKGREEN)

        xd  = int(header['NAXIS1']) 
        yd  = int(header['NAXIS2'])    
        zd  = int(header['NAXIS3'])    
        data = data / 256. #from fix to 32
        data = np.ascontiguousarray(data)

        #/ PHI_FITS_FPA_settings 
        # FPIMGCMD= 8 / FPA image command 
        # FPA_SROW= 0 / FPA start row setting FPA_EROW= 1022 / FPA end row setting 
        # FPA_NIMG= 20 / FPA number of images set FPEXPSTC= 1592452786 / [s] FPA exposure start time coarse 
        # FPEXPSTF= 699245 / [us] FPA exposure start time fine 
        # INTTIME = 0.01 / [s] Exposure time of single readout 
        # TELAPSE = 58.1974400877953 / [s] 
        # Elapsed time between start and end of obser
        # NSUMEXP = 480 / Number of detector readouts 
        # XPOSURE = 4.8 / [s] Total effective exposure time 
        # ACCLENGT= 4194304 / ACCU number of pixel set 
        # ACCNROWS= 6 / ACCU number of rows set 
        # ACCROWIT= 1 / ACCU number of row iterations set 
        # ACCNCOLS= 4 / ACCU number of columns set 
        # ACCCOLIT= 1 / ACCU number of column iterations set 
        # ACCACCUM= 20 / ACCU number of accumulations set 
        # ACCADDR = 0 / ACCU readout address (start) 

    except Exception:
        printc("ERROR, Unable to open fits file: {}",data_filename,color=bcolors.FAIL)
        return 0

    header['history'] = ' Data processed with phifdt_pipe.py '+ version
    header['history'] = '      and time '+ str(datetime.datetime.now())
    header['history'] = ' Parameters normalize_flat: '+ str(norm_f)
    header['history'] = ' Parameters flat_scaling: '+ str(flat_scaling)
    header['history'] = ' Parameters shrink_mask: '+ str(shrink_mask)
    header['history'] = ' Parameters center_method: '+ str(center_method)
    header['history'] = ' Parameters Hough: '+ str(hough_params)

    if verbose:
        plib.show_one(data[0,:,:],vmin=0,xlabel='pixel',ylabel='pixel',title='Data first image raw (1 of 24)',cbarlabel='DN',save=None,cmap='gray')
    
    #    * CAL_RTE=                990510 / ok
    #    * CAL_SCIP= 'None'               / Onboard scientific data analysis
    #    * RTE_ITER=           4294967295 / Number RTE inversion iterations
    #    * PHIDATID= '142010402'          / PHI dataset Id

    #-----------------
    # TAKE DATA DIMENSIONS AND SCALING
    #-----------------
    PXBEG1  = int(header['PXBEG1']) - 1           
    PXEND1  = int(header['PXEND1']) - 1          
    PXBEG2  = int(header['PXBEG2']) - 1           
    PXEND2  = int(header['PXEND2']) - 1   
    printc('Dimensions: ',PXBEG1, PXEND1, PXBEG2, PXEND2,color=bcolors.OKGREEN)

    if xd != (PXEND1 - PXBEG1 + 1) or yd != (PXEND2 - PXBEG2 + 1):
        printc('ERROR, Keyword dimensions and data array dimensions dont match ',color=bcolors.FAIL)
        return 0
    if xd < 2047:    
        printc('         data cropped to: [',PXBEG1,',',PXEND1,'],[',PXBEG2,',',PXEND2,']',color=bcolors.WARNING)
    
    data_scale = fits_get(data_filename,scaling = True)


    # STEP 5
    #-----------------
    # ROLL DATA TODO: This has to be removed in the future.
    #-----------------

    #-----------------
    # GET INFO ABOUT VOLTAGES/WAVELENGTHS, determine continuum and new flat
    #-----------------
    printc('-->>>>>>> Obtaining voltages from data ',color=bcolors.OKGREEN)
    wave_axis,voltagesData,tunning_constant,cpos,ref_wavelength = fits_get_sampling(data_filename)  
    printc('          Data FG voltages: ',voltagesData,color=bcolors.OKBLUE)
    printc('          Continuum position at wave: ', cpos,color=bcolors.OKBLUE)
    printc('          Data ref_wavelength [mA]: ',ref_wavelength,color=bcolors.OKBLUE)
    printc('          Data wave axis [mA]: ',wave_axis,color=bcolors.OKBLUE)
    printc('          Data wave axis - axis[0] [mA]: ',wave_axis - wave_axis[0],color=bcolors.OKBLUE)
    dummy_1 = (voltagesData-np.roll(voltagesData,-1))*(tunning_constant*1000)
    dummy_2 = np.sort(np.abs(dummy_1))
    sampling = np.mean(dummy_2[0:-2])
    printc('          Data average sampling [mA]: ',sampling,' using tunning constant: ',(tunning_constant*1000),color=bcolors.OKBLUE)
    #-----------------
    # ROLL DATA IF CONTINUUM IS IN DIFFERENT POSITION 
    # Probably before demodulation and flat is better!!!!
    #-----------------
    if cpos != 0:
        printc('          Rolling data to move continuum from right (red) to left (blue)',color=bcolors.WARNING)
        if voltagesData[cpos] < voltagesData[0]:
            printc('            The continuum was TAKEN in the BLUE, stored in the RED, but we want it in the BLUE *',color=bcolors.WARNING)
            data = np.roll(data,4,axis=0)
            voltagesData = np.roll(voltagesData,1,axis=0)
            wave_axis = np.roll(wave_axis,1,axis=0)

        elif voltagesData[cpos] > voltagesData[0]:
            printc('            The continuum was TAKEN in the RED but we want it in the BLUE',color=bcolors.WARNING)
            data = np.roll(data,4,axis=0)
            voltagesData = np.roll(voltagesData,1,axis=0)
            wave_axis = np.roll(wave_axis,1,axis=0)
        else:
            printc('            * NO ROLLING *',color=bcolors.FAIL)

        cpos = 0
        printc('          New FG voltages: ',voltagesData,color=bcolors.OKBLUE)
        printc('          NEW continuum position at wave: ', cpos,color=bcolors.OKBLUE)
        printc('          NEW data wave axis [mA]: ',wave_axis,color=bcolors.OKBLUE)

    #CHANGE TO 4D      
    data = np.reshape(data,(zd//4,4,yd,xd))


    # STEP 6
    #-----------------
    # CORRECT DARK 
    #-----------------
    
    if dark_c:
        data,header = phi_apply_dark(dark,dark_scale,dark_header,dark_DID,data,data_scale,header,verbose = verbose)
    else:
        printc('-->>>>>>> Skiping dark correction                   ',color=bcolors.WARNING)


    # STEP 7
    #-----------------
    # TODO: INTERPOLATE THE FLAT TO MATCH THE WAVELENG (CAVITY)
    #-----------------
    
    # from scipy.interpolate import RegularGridInterpolator
    # x = np.linspace(0,2047,2048).astype(int)
    # y = np.linspace(0,2047,2048).astype(int)
    # z = np.array([-300.,-140.,-70.,0.,70.,140.,300.]) #ojo con el -300
    # zn = np.array([-175.,-140.,-105.,-70.,-35.,0.,35.,70.,105.,140.,175.,300.])

    # flat_rsw1 = np.concatenate(((flat_rsw1[5,:,:,:])[np.newaxis,:,:,:],flat_rsw1))
    # fn = RegularGridInterpolator((z,y,x), flat_rsw1[:,0,:,:])
    # pts = np.array([-40,10,10])
    # print(fn(pts))

    #     pts = np.meshgrid(-40.,y,x)
    # pts = np.array([m.flatten() for m in pts])
    # flat_n = fn(pts.T)
    # result = flat_n.reshape((2048,2048))
    # plt.imshow(result,vmin=0.9,vmax=1.1)

    # flat_n = np.zeros((12,4,2048,2048))

    # for i in range(4):
    #   fn = RegularGridInterpolator((z,y,x), flat_rsw1[:,i,:,:],bounds_error=False)
    #   for j in range(12):
    #     print(i,zn[j])
    #     pts_list = np.meshgrid(zn[j],y,x)
    #     pts = np.array([m.flatten() for m in pts_list])
    #     flat_n[j,i,:,:] = fn(pts.T).reshape((2048,2048))


    # STEP 8
    #-----------------
    # APPLY FLAT CORRECTION 
    # TODO: TAKE THE REAL FLAT 
    #-----------------

    if flat_c:
        printc('-->>>>>>> Correcting Flatfield',color=bcolors.OKGREEN)

        if norm_f:
            rfx=[1024-200,1024+200]
            rfy=[1024-200,1024+200]
            print('          normalizing flats using region x = [',rfx[0],':',rfx[1],'] y = ]',rfy[0],':',rfy[1],']')
        else:
            flat_mean = 1.0

        for l in range(int(zd//4)):
            for p in range(4):
                if verbose:
                    print('          ... pol: ',p,' wave: ',l)

                if norm_f:
                    flat_mean = np.mean(flat[l,p,rfy[0]:rfy[1],rfx[0]:rfx[1]])

                data[l,p,:,:] = data[l,p,:,:] / (flat[l,p,PXBEG2:PXEND2+1,PXBEG1:PXEND1+1] / float(flat_scaling) / flat_mean )

        # locations = find_string(flat_f,'_')
        # try:
        #     DID_flat = flat_f[locations[-1]+1:locations[-1]+10]
        #     print('DID: ',np.float(DID_flat))
        # except:
        #     DID_flat = flat_f[:-4]
        #     printc("Unable to get DID from: {}",flat_f,color=bcolors.WARNING)         
        #     locations = find_string(dark_f,'/')
        #     DID_flat = flat_f[locations[-1]+1:]
        #     printc('DID: ',DID_flat,' -->> WILL NOT BE A NUMBER',color=bcolors.WARNING)

        if 'CAL_FLAT' in header:  # Check for existence
            header['CAL_FLAT'] = flat_DID
        else:
            header.set('CAL_FLAT', flat_DID, 'Onboard calibrated for gain table',after='CAL_DARK')

        if verbose:
            plib.show_one(data[cpos,0,:,:],vmax=None,vmin=0,xlabel='pixel',ylabel='pixel',title='Data / flat at continuum',cbarlabel='DN',save=None,cmap='gray')

    # STEP 9
    #-----------------
    # CORRECT PREFILTER 
    #-----------------

    if prefilter:
        data,header  = phi_correct_prefilter(prefilter_fits,header,data,voltagesData,verbose = verbose)

    # STEP 11
    #-----------------
    # FIND DATA CENTER 
    #-----------------

    printc('-->>>>>>> finding the center of the solar disk (needed for masking) ',color=bcolors.OKGREEN)
    try:
        if center_method == 'Hough':
            inner_radius,outer_radius,steps = hough_params
            c, radius,threshold = find_circle_hough(data[0,0,:,:],inner_radius,outer_radius,steps,threshold = 0.01,normalize=False,verbose=False)
            #c = np.roll(c,1)
            cx = c[0]
            cy = c[1]
            #TBE PUT IN CORRECT UNITS
        elif center_method  == 'circlefit':
            cy,cx,radius=find_center(data[0,0,:,:])  #OJO Cy... Cx
            c = np.array([int(cx),int(cy)])   #El vector es [0,1,2,...] == [x,y,z,...] == [cx,cy,cz,...] Pero esto ultimo esta al reves
            radius = int(radius)
        elif center_method == None:
            #get from header
            cx = header['CRPIX1']
            cy = header['CRPIX2']
            c = np.array([int(cx),int(cy)])   #El vector es [0,1,2,...] == [x,y,z,...] == [cx,cy,cz,...] Pero esto ultimo esta al reves
            radius = header['RSUN_ARC']/header['CDELT1']
        else:  
            raise ValueError("ERROR in center determination method - check input 'circlefit','Hough',null/None") 
    except ValueError as err:
        print(err.args)
        return 0

    #Uptade header with new centers
    if center_method == 'Hough' or center_method  == 'circlefit':
        printc('          Uptade header with new center:',color=bcolors.OKBLUE)
        printc('          OLD center:',color=bcolors.OKBLUE)
        printc('                  at: CRPIX1[x]=',header['CRPIX1'],' CRPIX2[y]=',header['CRPIX2'],' radius=',radius,color=bcolors.OKBLUE)
        header['history'] = ' CRPIX 1 and CRPIX2 uptated from ' + str(header['CRPIX1'])+ ' and ' + str(header['CRPIX2'])
        header['CRPIX1'] = (round(cx, 2))
        header['CRPIX2'] = (round(cy, 2))
        printc('          NEW center:',color=bcolors.OKBLUE)
        printc('                  at: CRPIX1[x]=',header['CRPIX1'],' CRPIX2[y]=',header['CRPIX2'],' radius=',radius,color=bcolors.OKBLUE)
        printc('ATTENTION: Keywords CRVAL1 and CRVAL2 are NOT updated but should be SET to zero!!!!',color=bcolors.FAIL)
    else:
        printc('          Using header image center:',color=bcolors.OKBLUE)
        printc('                  at: CRPIX1[x]=',header['CRPIX1'],' CRPIX2[y]=',header['CRPIX2'],' radius=',radius,color=bcolors.OKBLUE)

    #OJO.
    # find_circle_hough devuelve c = c[0] = x and c[1] = y !!!!!!!!!!!!!!
    # Esto viene porque en el KLL esta definido así (al reves) en la rutina votes()
 
     # STEP 11
    #-----------------
    # GHOST CORRECTION  (NEEDS INFO FROM DISK CENTER!!!)
    #-----------------

    if correct_ghost:
        data,header = phi_correct_ghost(data,header,radius,verbose = True)

    #-----------------
    # TAKE ONLY DISK WITH MARGIN
    #-----------------
    printc('-->>>>>>> Creating a mask for RTE with ',shrink_mask,' px margin')
    size_of_mask = radius - shrink_mask
    rx = [int(c[0]-size_of_mask),int(c[0]+size_of_mask)]
    ry = [int(c[1]-size_of_mask),int(c[1]+size_of_mask)]
    mask,coords = generate_circular_mask([xd-1,yd-1],size_of_mask,size_of_mask)
    mask = shift(mask, shift=(c[0]-xd//2,c[1]-yd//2), fill_value=0)
    printc('   RX = ', rx, 'RY = ', ry, color=bcolors.WARNING)

    factor = 0.05
    rrx = [int(c[0]-radius*factor),int(c[0]+radius*factor)]
    rry = [int(c[1]-radius*factor),int(c[1]+radius*factor)]

    #-----------------
    # REALIGN DATA BEFORE DEMODULATION
    #-----------------
    if realign:
        printc('-->>>>>>> Realigning data...           ',color=bcolors.OKGREEN)
        for i in range(zd//4):
            s_x,s_y,_ = PHI_shifts_FFT(data[i,:,:,:],prec=500,verbose=verbose,norma=False)
            for j in range(4):
                data[i,j,:,:] = shift_subp(data[i,j,:,:], shift=[s_x[j],s_y[j]]) #estra y,z asi que esta al reves FFT
        if 'CAL_REAL' in header:  # Check for existence
            header['CAL_REAL'] = 'FFT'
        else:
            header.set('CAL_REAL', 'FFT', 'Realigment of data (phifdt_pipe_modules.py)',after='CAL_DARK')

    #-----------------
    # APPLY DEMODULATION 
    #-----------------
    printc('-->>>>>>> Demodulating data...         ',color=bcolors.OKGREEN)
    if debug:
        datan = np.copy(data)
        ds = np.copy(data)
        demodM  = np.array([[0.168258,      0.357277,     0.202212,     0.273266],\
            [-0.660351,     0.314981,     0.650029,    -0.299685],\
            [ 0.421242,     0.336994,    -0.183068,    -0.576202],\
            [-0.351933,     0.459820,    -0.582167,     0.455458]])
        for i in range(zd//4):
            for l in range(xd):
                for m in range(yd):
                    datan[i,:,m,l] = np.matmul(demodM, ds[i,:,m,l] )
        plib.show_four_row(datan[3,0,:,:],datan[3,1,:,:],datan[3,2,:,:],datan[3,3,:,:],svmin=[0,-0.2,-0.2,-1.],svmax=[100,0.1,0.1,0.1])

    data, header = phi_apply_demodulation(data,instrument,header=header)

    if verbose == 1:
        plib.show_four_row(data[3,0,:,:],data[3,1,:,:],data[3,2,:,:],data[3,3,:,:],title=['I','Q','U','V'],svmin=[0,-0.004,-0.004,-0.004],svmax=[1.2,0.004,0.004,0.004])

    # with pyfits.open(data_filename) as hdu_list:
    #     hdu_list[0].data = data
    #     hdu_list[0].header = header
    #     hdu_list.writeto('dummy.fits', clobber=True)

    #-----------------
    # APPLY NORMALIZATION 
    #-----------------
    printc('-->>>>>>> Applying normalization --',color=bcolors.OKGREEN)
    nrm = np.mean(data[cpos,0,rry[0]:rry[1],rrx[0]:rrx[1]])
    print('          Norma is: ',nrm,' evaluated in x = [',rrx[0],':',rrx[1],'] y = [',rry[0],':',rry[1],']')
    data = data/nrm

    if 'CAL_NORM' in header:  # Check for existence
        header['CAL_NORM'] = np.round(nrm,6)
    else:
        header.set('CAL_NORM', np.round(nrm,6), 'Normalization constant PROC_Ic',after='CAL_DARK')

    if debug:
        datan = datan/nrm

    if debug:
        plib.show_four_row(data[3,0,:,:],data[3,1,:,:],data[3,2,:,:],data[3,3,:,:])
        plib.show_four_row(datan[3,0,:,:],datan[3,1,:,:],datan[3,2,:,:],datan[3,3,:,:])

    if verbose == 1:
        plib.show_four_row(data[3,0,:,:],data[3,1,:,:],data[3,2,:,:],data[3,3,:,:],title=['I','Q','U','V'],svmin=[0,-0.004,-0.004,-0.004],svmax=[1.2,0.004,0.004,0.004])

    #-----------------
    # GHOST CORRECTION  AFTER DEMODULATION
    #-----------------

    # if correct_ghost:
    #     data,header = phi_correct_ghost_dm(data,header,radius,verbose = verbose)

    #-----------------
    # CROSS-TALK CALCULATION 
    #-----------------
    if ItoQUV or putmediantozero:
            factor_media = 0.8  # 80% of the disk
            rrx_m = [int(c[0]-radius*factor_media),int(c[0]+radius*factor_media)]
            rry_m = [int(c[1]-radius*factor_media),int(c[1]+radius*factor_media)]
            maski,coords = generate_circular_mask([xd-1,yd-1],radius*factor_media,radius*factor_media)
            maski = shift(maski, shift=(c[0]-xd//2,c[1]-yd//2), fill_value=0).astype(int)

    if ItoQUV:
        printc('-->>>>>>> Cross-talk correction from Stokes I to Stokes Q,U,V --',color=bcolors.OKGREEN)
        printc('          Using ',factor_media*100,'% of the disk                     ',color=bcolors.OKGREEN)
        printc('          Crosstalk evaluated in x = [',rrx_m[0],':',rrx_m[1],'] y = [',rry_m[0],':',rry_m[1],']',' using ',factor_media*100,"% of the disk",color=bcolors.OKBLUE)

        if ind_wave:
            for i in range(zd//4):
                printc('          Individual wavelengths....',color=bcolors.OKBLUE)
                broadcastd = data[i,:,rry_m[0]:rry_m[1],rrx_m[0]:rrx_m[1]]
                data_dummy = data[:,:,rry_m[0]:rry_m[1],rrx_m[0]:rrx_m[1]]*0. + broadcastd[np.newaxis,:,:,:]
                cQ,cU,cV = crosstalk_ItoQUV(data_dummy[:,:,rry_m[0]:rry_m[1],rrx_m[0]:rrx_m[1]],npoints=10000,verbose=verbose)
                #-----------------
                # CROSS-TALK CORRECTION 
                #-----------------
                printc('          Applying cross-talk correction...',color=bcolors.OKGREEN)
                data[i,1,:,:] = data[i,1,:,:] - cQ[0]*data[i,0,:,:] - cQ[1]
                data[i,2,:,:] = data[i,2,:,:] - cU[0]*data[i,0,:,:] - cU[1]
                data[i,3,:,:] = data[i,3,:,:] - cV[0]*data[i,0,:,:] - cV[1]
            if verbose:
                plt.hist(data[0,1,maski > 0].flatten(), bins='auto')
                plt.title('Stokes Q')
                plt.hist(data[0,2,maski > 0].flatten(), bins='auto')
                plt.title('Stokes U')
                plt.hist(data[0,3,maski > 0].flatten(), bins='auto')
                plt.title('Stokes V')

                plt.show()
        else:
            cQ,cU,cV = crosstalk_ItoQUV(data[:,:,rry_m[0]:rry_m[1],rrx_m[0]:rrx_m[1]],verbose=verbose,npoints=10000)

        # rrx = [int(c[1]),int(c[1]+r*factor)]
        # rry = [int(c[0]-r*factor),int(c[0])]
        # cQ,cU,cV = crosstalk_ItoQUV(data[:,:,rry[0]:rry[1],rrx[0]:rrx[1]],verbose=verbose,npoints=10000)
        # rrx = [int(c[1]-r*factor),int(c[1])]
        # rry = [int(c[0]),int(c[0]+r*factor)]
        # cQ,cU,cV = crosstalk_ItoQUV(data[:,:,rry[0]:rry[1],rrx[0]:rrx[1]],verbose=verbose,npoints=10000)
        # return
        #-----------------
        # CROSS-TALK CORRECTION 
        #-----------------
            printc('          Applying cross-talk correction...',color=bcolors.OKGREEN)
            data[:,1,:,:] = data[:,1,:,:] - cQ[0]*data[:,0,:,:] - cQ[1]
            data[:,2,:,:] = data[:,2,:,:] - cU[0]*data[:,0,:,:] - cU[1]
            data[:,3,:,:] = data[:,3,:,:] - cV[0]*data[:,0,:,:] - cV[1]

        if verbose:
            plib.show_hist(data[0,1, maski > 0].flatten(), bins='auto',title=' ',leave = 'open',color='green')
            plib.show_hist(data[0,2, maski > 0].flatten(), bins='auto',title=' ',leave = 'open',color='red')
            plib.show_hist(data[0,3, maski > 0].flatten(), bins='auto',title='Stokes Q/U/V - no zero',color='blue')
            plib.show_four_row(data[2,0,:,:],data[2,1,:,:],data[2,2,:,:],data[2,3,:,:],title=['I - corr','Q - corr','U - corr','V - corr'],zoom=3,svmin=[0,-0.004,-0.004,-0.004],svmax=[1.2,0.004,0.004,0.004])
        # PLT_RNG = 2
        # plib.show_four_row(data[1,0,:,:],data[1,1,:,:],data[1,2,:,:],data[1,3,:,:],title=['I','Q','U','V'],svmin=[0.1,-0.002,-0.002,-0.003],svmax=[1.1,0.002,0.002,0.003])#,save='t1_'+str(loopthis)+'.png')
        # plib.show_four_row(data[3,0,:,:],data[3,1,:,:],data[3,2,:,:],data[3,3,:,:],title=['I','Q','U','V'],svmin=[0.1,-0.002,-0.002,-0.003],svmax=[1.1,0.002,0.002,0.003])#,save='t3_'+str(loopthis)+'.png')
        # plib.show_four_row(data[5,0,:,:],data[5,1,:,:],data[5,2,:,:],data[5,3,:,:],title=['I','Q','U','V'],svmin=[0.1,-0.002,-0.002,-0.003],svmax=[1.1,0.002,0.002,0.003])#,save='t5_'+str(loopthis)+'.png')

        # np.save('data_dummy',data)
        if 'CAL_CRT0' in header:  # Check for existence
            header['CAL_CRT0'] = np.round(cQ[0]*100,3)
        else:
            header.set('CAL_CRT0', np.round(cQ[0]*100,3), 'cross-talk I to Q (slope in %), wrt CAL_NROM ',after='CAL_DARK')

        if 'CAL_CRT1' in header:  # Check for existence
            header['CAL_CRT1'] = np.round(cQ[1]*100,3)
        else:
            header.set('CAL_CRT1', np.round(cQ[1]*100,3), 'cross-talk I to Q (off-set in %),  wrt CAL_NROM ',after='CAL_CRT0')

        if 'CAL_CRT2' in header:  # Check for existence
            header['CAL_CRT2'] = np.round(cU[0]*100,3)
        else:
            header.set('CAL_CRT2', np.round(cU[0]*100,3), 'cross-talk I to U (slope in %) alue,  wrt CAL_NROM ',after='CAL_CRT1')

        if 'CAL_CRT3' in header:  # Check for existence
            header['CAL_CRT3'] = np.round(cU[1]*100,3)
        else:
            header.set('CAL_CRT3', np.round(cU[1]*100,3), 'cross-talk I to U (off-set in %),  wrt CAL_NROM ',after='CAL_CRT2')

        if 'CAL_CRT4' in header:  # Check for existence
            header['CAL_CRT4'] = np.round(cV[0]*100,3)
        else:
            header.set('CAL_CRT4', np.round(cV[0]*100,3), 'cross-talk I to V (slope in %),  wrt CAL_NROM',after='CAL_CRT3')

        if 'CAL_CRT5' in header:  # Check for existence
            header['CAL_CRT5'] = np.round(cV[1]*100,3)
        else:
            header.set('CAL_CRT5', np.round(cV[1]*100,3), 'cross-talk I to V (off-set in %),  wrt CAL_NROM ',after='CAL_CRT4')

    #-----------------
    # CROSS-TALK CALCULATION FROM V TO QU (Interactive)
    #-----------------
    
    if VtoQU:
        printc('-->>>>>>> Cross-talk correction from Stokes V to Stokes Q,U ',color=bcolors.OKGREEN)

        factor = 0.3 # 30% of the disk
        rrx = [int(c[0]-radius*factor),int(c[0]+radius*factor)]
        rry = [int(c[1]-radius*factor),int(c[1]+radius*factor)]
        print(' Cross-talk evaluated in x = [',rrx[0],':',rrx[1],'] y = [',rry[0],':',rry[1],']',' using ',factor*100,"% of the disk")
        cVQ,cVU = cross_talk_QUV(data[:,:,rry[0]:rry[1],rrx[0]:rrx[1]],nran = 2000,nlevel=nlevel,block=False)

        option = input('Do you want to apply the correction (y/n) [n]: ')
        if option == 'y':
            datao = np.copy(data)
            print('Applying V to QU cross-talk correction...')
            datao[:,1,:,:] = data[:,1,:,:] - cVQ[0]*data[:,3,:,:] - cVQ[1]
            datao[:,2,:,:] = data[:,2,:,:] - cVU[0]*data[:,3,:,:] - cVU[1]
            plib.show_two(data[3,1,ry[0]:ry[1],rx[0]:rx[1]],datao[3,1,ry[0]:ry[1],rx[0]:rx[1]],block=False,title=['Stokes Q','Stokes Q corrected'],zoom=3)
            plib.show_two(data[3,2,ry[0]:ry[1],rx[0]:rx[1]],datao[3,2,ry[0]:ry[1],rx[0]:rx[1]],block=False,title=['Stokes U','Stokes U corrected'],zoom=3)
            option2 = input('Do you wnat to continue (y/n) [n]: ')
            if option2 == 'y':
                data = np.copy(datao)
                del datao
        plt.close()

        if 'CAL_CRT6' in header:  # Check for existence
            header['CAL_CRT6'] = np.round(cVQ[0]*100,3)
        else:
            header.set('CAL_CRT6', np.round(cVQ[0]*100,3), 'cross-talk V to Q  (slope in %),  wrt CAL_NROM ',after='CAL_CRT5')

        if 'CAL_CRT7' in header:  # Check for existence
            header['CAL_CRT7'] = np.round(cVQ[1]*100,3)
        else:
            header.set('CAL_CRT7', np.round(cVQ[1]*100,3), 'cross-talk V to Q (off-set in %),  wrt CAL_NROM ',after='CAL_CRT6')

        if 'CAL_CRT8' in header:  # Check for existence
            header['CAL_CRT8'] = np.round(cVU[0]*100,3)
        else:
            header.set('CAL_CRT8', np.round(cVU[0]*100,3), 'cross-talk V to U (slope in %),  wrt CAL_NROM ',after='CAL_CRT7')

        if 'CAL_CRT9' in header:  # Check for existence
            header['CAL_CRT9'] = np.round(cVU[1]*100,3)
        else:
            header.set('CAL_CRT9', np.round(cVU[1]*100,3), 'cross-talk V to U (off-set in %),  wrt CAL_NROM ',after='CAL_CRT8')

    #-----------------
    # CROSS-TALK CALCULATION FROM I TO QUV (2D)
    #-----------------

    if do2d >= 2:
        printc('---------------------------------------------------------',color=bcolors.OKGREEN)
        printc('-- IN 2-Dimensions                                     --')
        printc('-- Cross-talk correction from Stokes I to Stokes Q,U,V --')
        printc('---------------------------------------------------------',color=bcolors.OKGREEN)
        size = do2d
        cV0,cV1 = crosstalk_ItoQUV2d(data[:,:,ry[0]:ry[1],rx[0]:rx[1]],size=size)
        nsize = size-1
        dim = ry[1]-ry[0]-nsize
        cV0 = cV0.reshape(dim,dim)
        cV1 = cV1.reshape(dim,dim)
        plib.show_one(cV0,vmin=-0.005,vmax=0.005)
        data[:,3,ry[0]+nsize//2:ry[1]-nsize//2-1,rx[0]+nsize//2:rx[1]-nsize//2-1] = \
            data[:,3,ry[0]+nsize//2:ry[1]-nsize//2-1,rx[0]+nsize//2:rx[1]-nsize//2-1] -\
            cV0*data[:,0,ry[0]+nsize//2:ry[1]-nsize//2-1,rx[0]+nsize//2:rx[1]-nsize//2-1] #- 0.95*cV1

    #-----------------
    # FRINGING - 
    #-----------------

    if correct_fringes == 'auto' or correct_fringes == 'manual':
        if verbose:
            plib.show_four_row(data[2,0,:,:],data[2,1,:,:],data[2,2,:,:],data[2,3,:,:],title=['I - before fringe','Q','U','V'],zoom=3,svmin=[0,-0.004,-0.004,-0.004],svmax=[1.2,0.004,0.004,0.004])
        data, header = phi_correct_fringes(data,header,option=correct_fringes,verbose=verbose)
        if verbose:
            plib.show_four_row(data[2,0,:,:],data[2,1,:,:],data[2,2,:,:],data[2,3,:,:],title=['I - after fringe','Q','U','V'],zoom=3,svmin=[0,-0.004,-0.004,-0.004],svmax=[1.2,0.004,0.004,0.004])
    elif correct_fringes == False:
        pass
    else:
        printc('Error in option finge correction. Options are "manual", "auto" or false. Given: ',color=bcolors.WARNING)
        print(correct_fringes)
    #-----------------
    # MEDIAN TO CERO
    #-----------------

    if putmediantozero:
        printc('-->>>>>>> Putting median to zero ',color=bcolors.OKGREEN)
        printc('          Median evaluated in x = [',rrx_m[0],':',rrx_m[1],'] y = [',rry_m[0],':',rry_m[1],']',' using ',factor*100,"% of the disk",color=bcolors.OKBLUE)
        for i in range(zd//4):
            PQ = np.median( data[i,1, maski > 0])#,axis=(1,2))
            PU = np.median( data[i,2, maski > 0])#,axis=(1,2))
            PV = np.median( data[i,3, maski > 0])#,axis=(1,2))
        # PQ = np.median(data[:,1,rry[0]:rry[1],rrx[0]:rrx[1]],axis=(1,2))
        # PU = np.median(data[:,2,rry[0]:rry[1],rrx[0]:rrx[1]],axis=(1,2))
        # PV = np.median(data[:,3,rry[0]:rry[1],rrx[0]:rrx[1]],axis=(1,2))
            data[i,1,:,:] = data[i,1,:,:] - PQ#[:,np.newaxis,np.newaxis]
            data[i,2,:,:] = data[i,2,:,:] - PU#[:,np.newaxis,np.newaxis]
            data[i,3,:,:] = data[i,3,:,:] - PV#[:,np.newaxis,np.newaxis]
            printc(PQ,PU,PV)
    if verbose == 1:
        plib.show_hist(data[0,1, maski > 0].flatten(), bins='auto',title=' ',leave='open',color='green')
        plib.show_hist(data[0,2, maski > 0].flatten(), bins='auto',title=' ',leave='open',color='red')
        plib.show_hist(data[0,3, maski > 0].flatten(), bins='auto',title='Stokes Q/U/V - zero',color='blue')
        plib.show_four_row(data[3,0,:,:],data[3,1,:,:],data[3,2,:,:],data[3,3,:,:],title=['I','Q','U','V'],zoom=3,svmin=[0,-0.004,-0.004,-0.004],svmax=[1.2,0.004,0.004,0.004])

        header['history'] = ' Parameters putmediantozero [%]: '+ str(np.round(PQ*100,6))+ ' '+ str(np.round(PU*100,6))+ ' '+ str(np.round(PV*100,6))

    #-----------------
    #CHECK FOR INFs
    #-----------------

    data[np.isinf(data)] = 0
    data[np.isnan(data)] = 0

    #-----------------
    # SAVE DATA TODO: CMILOS FORMAT AND FITS
    #-----------------

    #check if npz,pngs and level2 exist
    dirs = ['npz','pngs','level2']
        
    for checkit in dirs:
        check_dir = os.path.isdir(output_dir+checkit)
        if not check_dir:
            os.makedirs(output_dir+checkit)
            print("created folder : ", output_dir+checkit)
        else:
            print(output_dir+checkit, "folder already exists.")


    printc('---------------------------------------------------------',color=bcolors.OKGREEN)
    if outfile == None:
        #basically replace L1 by L1.5
        try:
            outfile_L2 = set_level(data_f,'L1','L2')
            outfile_L2 = set_level(outfile_L2,'ilam','stokes')
        except:
            outfile_L2 = set_level(data_f,'L0','L2')
            outfile_L2 = set_level(outfile_L2,'ilam','stokes')

    printc(' Saving data to: ',output_dir+'level2/'+outfile_L2)

    # hdu = pyfits.PrimaryHDU(data)
    # hdul = pyfits.HDUList([hdu])
    # hdul.writeto(outfile, overwrite=True)

    with pyfits.open(data_filename) as hdu_list:
        hdu_list[0].data = data
    #        header = hdu_list[0].header
        hdu_list[0].header = header

        # Add a new key to the header
        # header.insert(20, ('NEWKEY', 'OMIT', 'test'))
        #header.set('NEWKEY','50.5')
        hdu_list.writeto(output_dir+'level2/'+outfile_L2, clobber=True)
    #        hdu_list.writeto(directory+outfile+'_L1.fits', clobber=True)

    # with pyfits.open(data_f) as hdu_list:
    #     hdu_list[0].data = mask
    #     hdu_list.writeto(directory+outfile+'_red-mask.fits', clobber=True)

    #-----------------
    # INVERSION OF DATA WITH CMILOS
    #-----------------
    if rte == 'RTE' or rte == 'CE' or rte == 'CE+RTE':

        printc('---------------------RUNNING CMILOS --------------------------',color=bcolors.OKGREEN)
        
        rte_invs = np.zeros((12,yd,xd)).astype(float)
        rte_invs[:,ry[0]:ry[1],rx[0]:rx[1]] = generate_level2(data[:,:,ry[0]:ry[1],rx[0]:rx[1]],wave_axis,rte,cmilos=cmilos)

        rte_invs_noth = np.copy(rte_invs)
        umbral = 3.

        noise_in_V =  np.mean(data[0,3,rry[0]:rry[1],rrx[0]:rrx[1]])
        low_values_flags = np.max(np.abs(data[:,3,:,:]),axis=0) < noise_in_V*umbral  # Where values are low
        rte_invs[2,low_values_flags] = 0
        rte_invs[3,low_values_flags] = 0
        rte_invs[4,low_values_flags] = 0
        for i in range(12):
            rte_invs[i,:,:] = rte_invs[i,:,:] * mask
        #save plots!!!!
        if verbose:
            plib.show_four_row(rte_invs_noth[2,:,:],rte_invs_noth[3,:,:],rte_invs_noth[4,:,:],rte_invs_noth[8,:,:],svmin=[0,0,0,-6.],svmax=[1200,180,180,+6.],title=['Field strengh [Gauss]','Field inclination [degree]','Field azimuth [degree]','LoS velocity [km/s]'],xlabel='Pixel',ylabel='Pixel')#,save=outfile+'_VLoS.png')
            plib.show_four_row(rte_invs[2,:,:],rte_invs[3,:,:],rte_invs[4,:,:],rte_invs[8,:,:],svmin=[0,0,0,-6.],svmax=[1200,180,180,+6.],title=['Field strengh [Gauss]','Field inclination [degree]','Field azimuth [degree]','LoS velocity [km/s]'],xlabel='Pixel',ylabel='Pixel')#,save=outfile+'BLoS.png')
        rte_invs_noth[8,:,:] = rte_invs_noth[8,:,:] - np.mean(rte_invs_noth[8,rry[0]:rry[1],rrx[0]:rrx[1]])
        rte_invs[8,:,:] = rte_invs[8,:,:] - np.mean(rte_invs[8,rry[0]:rry[1],rrx[0]:rrx[1]])

        #np.savez_compressed(output_dir+'npz/'+outfile_L2+'_RTE', rte_invs=rte_invs, rte_invs_noth=rte_invs_noth,mask=mask)

        b_los = rte_invs_noth[2,:,:]*np.cos(rte_invs_noth[3,:,:]*np.pi/180.)*mask
        b_los = rte_invs_noth[2,:,:]*np.cos(rte_invs_noth[3,:,:]*np.pi/180.)*mask
        b_los = rte_invs_noth[2,:,:]*np.cos(rte_invs_noth[3,:,:]*np.pi/180.)*mask
        b_los = rte_invs_noth[2,:,:]*np.cos(rte_invs_noth[3,:,:]*np.pi/180.)*mask
        # b_los = np.zeros((2048,2048))
        # b_los[PXBEG2:PXEND2+1,PXBEG1:PXEND1+1] = b_los_cropped

        v_los = rte_invs_noth[8,:,:] * mask
        # v_los = np.zeros((2048,2048))
        # v_los[PXBEG2:PXEND2+1,PXBEG1:PXEND1+1] = v_los_cropped
        if verbose:
            plib.show_one(v_los,vmin=-2.5,vmax=2.5,title='LoS velocity')
            plib.show_one(b_los,vmin=-30,vmax=30,title='LoS magnetic field')

        printc('  ---- >>>>> Updating L2 header.... ',color=bcolors.OKGREEN)

        header['history'] = ' RTE CMILOS INVERTER: '+ rte
        header['history'] = ' CMILOS VER: '+ version_cmilos

        if 'RTE_ITER' in header:  # Check for existence
            header['RTE_ITER'] = str(15)
        else:
            header.set('RTE_ITER', str(15), 'Number RTE inversion iterations',after='CAL_SCIP')

        printc('  ---- >>>>> Saving L2 data.... ',color=bcolors.OKGREEN)

        with pyfits.open(data_filename) as hdu_list:
            hdu_list[0].data = rte_invs_noth[2,:,:] * mask
    #            header = hdu_list[0].header
            hdu_list[0].header = header
            writeto = set_level(outfile_L2,'stokes','bmag')
            hdu_list.writeto(output_dir+'level2/'+writeto, clobber=True)

        # with pyfits.open(data_filename) as hdu_list:
            hdu_list[0].data = rte_invs_noth[3,:,:] * mask
            # hdu_list[0].header = header
            writeto = set_level(outfile_L2,'stokes','binc')
            hdu_list.writeto(output_dir+'level2/'+writeto, clobber=True)

        # with pyfits.open(data_filename) as hdu_list:
            hdu_list[0].data = rte_invs[4,:,:] * mask
            # hdu_list[0].header = header
            writeto = set_level(outfile_L2,'stokes','bazi')
            hdu_list.writeto(output_dir+'level2/'+writeto, clobber=True)

        # with pyfits.open(data_filename) as hdu_list:
            hdu_list[0].data = b_los
            # hdu_list[0].header = header
            writeto = set_level(outfile_L2,'stokes','blos')
            hdu_list.writeto(output_dir+'level2/'+writeto, clobber=True)

        # with pyfits.open(data_filename) as hdu_list:
            hdu_list[0].data = v_los
            # hdu_list[0].header = header
            writeto = set_level(outfile_L2,'stokes','vlos')
            hdu_list.writeto(output_dir+'level2/'+writeto, clobber=True)

        # with pyfits.open(data_filename) as hdu_list:
            hdu_list[0].data = rte_invs[9,:,:]+rte_invs[10,:,:]
            # hdu_list[0].header = header
            writeto = set_level(outfile_L2,'stokes','icnt')
            hdu_list.writeto(output_dir+'level2/'+writeto, clobber=True)

        printc('  ---- >>>>> Saving plots.... ',color=bcolors.OKGREEN)

        #-----------------
        # PLOTS VLOS
        #-----------------
        Zm = np.ma.masked_where(mask == 1, mask)

        plt.figure(figsize=(10, 10))
        ax = plt.gca()
        plt.title('PHI-FDT LoS velocity',size=20)

        # Hide grid lines
        ax.grid(False)
        # Hide axes ticks
        ax.set_xticks([])
        ax.set_yticks([])

    #        im = ax.imshow(np.fliplr(rotate(v_los[PXBEG2:PXEND2+1,PXBEG1:PXEND1+1], 52, reshape=False)), cmap='bwr',vmin=-3.,vmax=3.)
        im = ax.imshow(v_los, cmap='bwr',vmin=-3.,vmax=3.)

        divider = plib.make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        cbar = plib.plt.colorbar(im, cax=cax)
        cbar.set_label('[km/s]')
        cbar.ax.tick_params(labelsize=16)

        #ax.imshow(Zm, cmap='gray')
        writeto = set_level(outfile_L2,'stokes','vlos')
        writeto = set_level(writeto,'.fits','.png')
        plt.savefig(output_dir+'pngs/'+writeto,dpi=300)
        plt.close()

        #-----------------
        # PLOTS BLOS
        #-----------------

        plt.figure(figsize=(10, 10))
        ax = plt.gca()
        plt.title('PHI-FDT Magnetogram',size=20)

        # Hide grid lines
        ax.grid(False)
        # Hide axes ticks
        ax.set_xticks([])
        ax.set_yticks([])
                    
        #im = ax.imshow(np.fliplr(rotate(b_los[PXBEG2:PXEND2+1,PXBEG1:PXEND1+1], 52, reshape=False)), cmap='gray',vmin=-100,vmax=100) 
        im = ax.imshow(b_los, cmap='gray',vmin=-100,vmax=100)

        divider = plib.make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        cbar = plib.plt.colorbar(im, cax=cax)
        # cbar.set_label('Stokes V amplitude [%]')
        cbar.set_label('LoS magnetic field [Mx/cm$^2$]')
        cbar.ax.tick_params(labelsize=16)
        #ax.imshow(Zm, cmap='gray')

        writeto = set_level(outfile_L2,'stokes','blos')
        writeto = set_level(writeto,'.fits','.png')
        plt.savefig(output_dir+'pngs/'+writeto,dpi=300)
        plt.close()

        printc('--------------------- END  ----------------------------',color=bcolors.FAIL)

    return wave_axis
    # if rte == 'cog':
    #     printc('---------------------RUNNING COG --------------------------',color=bcolors.OKGREEN)
    #     wavelength = 6173.3356
    #     v_los,b_los = cog(data,wavelength,wave_axis,lande_factor=3,cpos = cpos)

    #     #-----------------
    #     # MASK DATA AND SAVE
    #     #-----------------

    #     v_los = v_los * mask
    #     b_los = b_los * mask
    #     plib.show_one(v_los,vmin=-1.5,vmax=1.5)
    #     plib.show_one(b_los,vmin=-150,vmax=150)
    #     if verbose == 1:
    #         plib.show_one(v_los,vmin=-2.5,vmax=2.5)
    #         plib.show_one(b_los,vmin=-150,vmax=150)

    #     with pyfits.open(data_f) as hdu_list:
    #         hdu_list[0].data = v_los
    #         hdu_list[0].header = header
    #         writeto = set_level(outfile_L2,'ilam','vlos-cog')
    #         writeto = set_level(writeto,'.fits','.png')
    #         plt.savefig(directory+writeto,dpi=300)

    #     with pyfits.open(data_f) as hdu_list:
    #         hdu_list[0].data = b_los
    #         hdu_list[0].header = header
    #         writeto = set_level(outfile_L2,'ilam','blos-cog')
    #         writeto = set_level(writeto,'.fits','.png')
    #         plt.savefig(directory+'pngs/'+writeto,dpi=300)

    # return
    #-----------------
    # CORRECT CAVITY
    #-----------------

    # try:
    #     if cavity == 0:
    #         cavity=np.zeros_like(vl)
    #         print("zerooooooooooo")
    # except:
    #     # cavity = cavity[ry[0]:ry[1],rx[0]:rx[1]]
    #     pass

    # factor = 0.5
    # rrx = [int(c[0]-r*factor),int(c[0]+r*factor)]
    # rry = [int(c[1]-r*factor),int(c[1]+r*factor)]
    # print(rrx,rry,' check these for los vel calib')
    # off = np.mean(vl[rry[0]:rry[1],rrx[0]:rrx[1]])
    # vl = vl - off #- cavity
    # print('velocity offset ',off)

    # # cavity,h = phi.fits_read('HRT_cavity_map_IP5.fits')
    # # cavity = cavity * 0.3513e-3/6173.*300000. #A/V 
    # # cavity = cavity - np.median(cavity[800:1200,800:1200])
    
    # return vl


